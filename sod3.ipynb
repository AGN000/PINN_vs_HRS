{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code is cusotmosed based on the root code provided in\n",
    "https://www.researchgate.net/publication/359480166_Discontinuity_Computing_using_Physics-Informed_Neural_Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 1455] The paging file is too small for this operation to complete. Error loading \"c:\\Users\\arung\\anaconda3\\envs\\Pytorch_gpu\\lib\\site-packages\\torch\\lib\\shm.dll\" or one of its dependencies.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\arung\\anaconda3\\envs\\Pytorch_gpu\\lib\\site-packages\\torch\\__init__.py:130\u001b[0m\n\u001b[0;32m    128\u001b[0m     err \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mWinError(last_error)\n\u001b[0;32m    129\u001b[0m     err\u001b[38;5;241m.\u001b[39mstrerror \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Error loading \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdll\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m or one of its dependencies.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 130\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    132\u001b[0m     is_loaded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 1455] The paging file is too small for this operation to complete. Error loading \"c:\\Users\\arung\\anaconda3\\envs\\Pytorch_gpu\\lib\\site-packages\\torch\\lib\\shm.dll\" or one of its dependencies."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import time\n",
    "import scipy.io\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "# Seeds\n",
    "torch.manual_seed(12)\n",
    "np.random.seed(12)\n",
    "x_min=0;\n",
    "x_max=1;\n",
    "t_max=0.15\n",
    "nx=101;\n",
    "nt=101\n",
    "ct=1\n",
    "er_c1=1e-3\n",
    "# er_c2=1e-4\n",
    "   \n",
    "# Calculate gradients using torch.autograd.grad\n",
    "def gradients(outputs, inputs):\n",
    "    return torch.autograd.grad(outputs, inputs,grad_outputs=torch.ones_like(outputs), create_graph=True)\n",
    "\n",
    "# Convert torch tensor into np.array\n",
    "def to_numpy(input):\n",
    "    if isinstance(input, torch.Tensor):\n",
    "        return input.detach().cpu().numpy()\n",
    "    elif isinstance(input, np.ndarray):\n",
    "        return input\n",
    "    else:\n",
    "        raise TypeError('Unknown type of input, expected torch.Tensor or ' \\\n",
    "                        'np.ndarray, but got {}'.format(type(input)))\n",
    "\n",
    "# Initial conditions\n",
    "def IC(x):\n",
    "    N = len(x)\n",
    "    rho_init = np.zeros((x.shape[0]))                                              \n",
    "    u_init = np.zeros((x.shape[0]))                                                \n",
    "    p_init = np.zeros((x.shape[0]))                                                \n",
    "\n",
    "    # rho, p - initial condition\n",
    "    for i in range(N):\n",
    "        if (x[i] <= 0.5):\n",
    "            rho_init[i] = 1.0\n",
    "            p_init[i] = 1.0\n",
    "        else:\n",
    "            rho_init[i] = 0.125\n",
    "            p_init[i] = 0.1\n",
    "\n",
    "    return rho_init, u_init, p_init\n",
    "\n",
    "# Generate Neural Network adative tanh(ax) activation function\n",
    "class ParamTanh(nn.Module):\n",
    "    def __init__(self, alpha):\n",
    "        super(ParamTanh, self).__init__()\n",
    "        self.alpha = nn.Parameter(torch.tensor(alpha, requires_grad=True))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.tanh(self.alpha * x)\n",
    "class DNN(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(DNN, self).__init__()\n",
    "        self.net = nn.Sequential()    \n",
    "        tn=15                                              \n",
    "        self.net.add_module('Linear_layer_1', nn.Linear(2, tn))                     \n",
    "        self.net.add_module('Tanh_layer_1', nn.Tanh())                              \n",
    "\n",
    "        for num in range(2, 5):                                                     \n",
    "            self.net.add_module('Linear_layer_%d' % (num), nn.Linear(tn, tn))       \n",
    "            self.net.add_module('Tanh_layer_%d' % (num), ParamTanh(alpha=0.9))                 \n",
    "        self.net.add_module('Linear_layer_final', nn.Linear(tn, 4))                 \n",
    "\n",
    "    # Forward Feed\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "    # Loss function for PDE\n",
    "    def loss_pde(self, x):\n",
    "        y = self.net(x)                                                \n",
    "        rho,p,u,nui = y[:, 0:1], y[:, 1:2], y[:, 2:3], y[:, 3:4]\n",
    "        \n",
    "        U2 = rho*u\n",
    "        U3 = 0.5*rho*u**2 + p/0.4\n",
    "        \n",
    "        #F1 = U2\n",
    "        F2 = rho*u**2+p\n",
    "        F3 = u*(U3 + p)\n",
    "        \n",
    "        gamma = 1.4                                                    \n",
    "\n",
    "        # Gradients and partial derivatives\n",
    "        drho_g = gradients(rho, x)[0]                                  \n",
    "        rho_t, rho_x = drho_g[:, :1], drho_g[:, 1:]         \n",
    "\n",
    "        drho_gg = gradients(rho_x, x)[0]      \n",
    "        rho_tx, rho_xx = drho_gg[:, 0], drho_gg[:, 1]  \n",
    "\n",
    "\n",
    "        du_g = gradients(u, x)[0]                                      \n",
    "        u_t, u_x = du_g[:, :1], du_g[:, 1:]                            \n",
    "\n",
    "       # dp_g = gradients(p, x)[0]                                     \n",
    "       # p_t, p_x = dp_g[:, :1], dp_g[:, 1:]                           \n",
    "        \n",
    "        dU2_g = gradients(U2, x)[0]\n",
    "        U2_t,U2_x = dU2_g[:,:1], dU2_g[:,1:]\n",
    "        d2U2_g = gradients(U2_x, x)[0]\n",
    "        U2_tx,U2_xx = d2U2_g[:,:1], d2U2_g[:,1:]\n",
    "        dU3_g = gradients(U3, x)[0]\n",
    "        U3_t,U3_x = dU3_g[:,:1], dU3_g[:,1:]\n",
    "        d2U3_g = gradients(U3_x, x)[0]\n",
    "        U3_tx,U3_xx = d2U3_g[:,:1], d2U3_g[:,1:]\n",
    "        dF2_g = gradients(F2, x)[0]\n",
    "        F2_t,F2_x = dF2_g[:,:1], dF2_g[:,1:]\n",
    "        dF3_g = gradients(F3, x)[0]\n",
    "        F3_t,F3_x = dF3_g[:,:1], dF3_g[:,1:]\n",
    "\n",
    "        d = 0.12*(abs(u_x)-u_x)  + 1 #+0.1*(abs(rho_x)-rho_x)\n",
    "        #d = 0.1*(abs(u_x))+1e-18\n",
    "        # d=1;\n",
    "        nu=nui**2\n",
    "     \n",
    "        f = (((rho_t + U2_x-nu*rho_xx)/d)**2).mean() + \\\n",
    "            (((U2_t  + F2_x-nu*U2_xx)/d)**2).mean() + \\\n",
    "            (((U3_t  + F3_x-nu*U3_xx)/d)**2).mean() +10**-2*((nu)**2).mean()\n",
    "           # ((rho_t).mean())**2  +\\\n",
    "           # ((U3_t).mean())**2 \n",
    "    \n",
    "        return f\n",
    "\n",
    "    # Loss function for initial condition\n",
    "    def loss_ic(self, x_ic, rho_ic, u_ic, p_ic):\n",
    "        y_ic = self.net(x_ic)                                                      \n",
    "        rho_ic_nn, p_ic_nn,u_ic_nn = y_ic[:, 0], y_ic[:, 1], y_ic[:, 2]            \n",
    "\n",
    "        # Loss function for the initial condition\n",
    "        loss_ics = ((u_ic_nn - u_ic) ** 2).mean() + \\\n",
    "               ((rho_ic_nn- rho_ic) ** 2).mean()  + \\\n",
    "               ((p_ic_nn - p_ic) ** 2).mean()\n",
    "\n",
    "        return loss_ics\n",
    "    \n",
    "#device = torch.device('cuda')         # change to cpu if you dont have a cuda device     \n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")  \n",
    "# os.remove('loss.dat')                       \n",
    "                                                \n",
    "                                             \n",
    "x = np.linspace(x_min, x_max, nx)                                   \n",
    "t = np.linspace(0, t_max, nt)                                     \n",
    "t_grid, x_grid = np.meshgrid(t, x)                                 \n",
    "T = t_grid.flatten()[:, None]                                      \n",
    "X = x_grid.flatten()[:, None]                                      \n",
    "#id_f = np.random.choice(num_x*num_t, num_f_train, replace=False)   \n",
    "# we use all llocation points because PINN is free from over fitting. If you wish you can use random\n",
    "x_int = X[:, 0][:, None]                                        \n",
    "t_int = T[:, 0][:, None]                                        \n",
    "x_int_train = np.hstack((t_int, x_int))   \n",
    "\n",
    "x = np.linspace(x_min, x_max, nx)                                   \n",
    "t = np.linspace(0, t_max, nt)                                       \n",
    "t_grid, x_grid = np.meshgrid(t, x)                                 \n",
    "T = t_grid.flatten()[:, None]                                      \n",
    "X = x_grid.flatten()[:, None]                                      \n",
    "x_ic = x_grid[:, 0][:, None]                                   \n",
    "t_ic = t_grid[:, 0][:, None]                                   \n",
    "x_ic_train = np.hstack((t_ic, x_ic))                               \n",
    "\n",
    "rho_ic_train, u_ic_train, p_ic_train = IC(x_ic)                    \n",
    "x_ic_train = torch.tensor(x_ic_train, dtype=torch.float32).to(device)\n",
    "x_int_train = torch.tensor(x_int_train, requires_grad=True, dtype=torch.float32).to(device)\n",
    "# x_int_train1 = torch.tensor(x_int_train1, requires_grad=True, dtype=torch.float32).to(device)\n",
    "rho_ic_train = torch.tensor(rho_ic_train, dtype=torch.float32).to(device)\n",
    "u_ic_train = torch.tensor(u_ic_train, dtype=torch.float32).to(device)\n",
    "p_ic_train = torch.tensor(p_ic_train, dtype=torch.float32).to(device)\n",
    "\n",
    "model = DNN().to(device)\n",
    "\n",
    "def closure():\n",
    "        optimizer.zero_grad()                                                     \n",
    "        loss_pde = model.loss_pde(x_int_train)                                    \n",
    "        loss_ic = model.loss_ic(x_ic_train, rho_ic_train,u_ic_train,p_ic_train)   \n",
    "        loss = loss_pde + 1*loss_ic                                          \n",
    "        loss.backward()\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001                                                           # Learning rate\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# %%\n",
    "epoch = 0\n",
    "epochi = epoch\n",
    "epochs = 1001\n",
    "tic = time.time()\n",
    "for epoch in range(1+epochi, epochs+epochi):\n",
    "    loss = optimizer.step(closure)\n",
    "    loss_value = loss.item() if not isinstance(loss, float) else loss\n",
    "    # Print total loss\n",
    "    print(f'epoch {epoch}: loss {loss_value:.6f}')\n",
    "        \n",
    "\n",
    "                                                      # Learning rate\n",
    "optimizer = torch.optim.LBFGS(model.parameters(),lr=0.1,max_iter=20)\n",
    "\n",
    "# %%\n",
    "\n",
    "epochi = epoch\n",
    "\n",
    "epochs = 501\n",
    "tic = time.time()\n",
    "for epoch in range(epochi, epochs+epochi):\n",
    "    loss = optimizer.step(closure)\n",
    "    loss_value = loss.item() if not isinstance(loss, float) else loss\n",
    "    if loss_value<er_c1:\n",
    "        # loss = optimizer.step(closure1)\n",
    "        # if loss_value<er_c2:\n",
    "            print('Converged')\n",
    "            break\n",
    "    # Print total loss\n",
    "    print(f'epoch {epoch}: loss {loss_value:.6f}')\n",
    "toc = time.time()\n",
    "# torch.save(model.state_dict(), 'so_model.pth')\n",
    "# print(f'Total training time: {toc - tic}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(x_min, x_max, ct*nx)                                   \n",
    "t = np.linspace(t_max, t_max, 1)                                     \n",
    "t_grid, x_grid = np.meshgrid(t, x)                               \n",
    "T = t_grid.flatten()[:, None]                                    \n",
    "X = x_grid.flatten()[:, None]                                    \n",
    "x_test = np.hstack((T, X))                                       \n",
    "x_test = torch.tensor(x_test, dtype=torch.float32).to(device)\n",
    "u_pred = to_numpy(model(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x,u_pred[:,0], marker='o', label='Circle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
